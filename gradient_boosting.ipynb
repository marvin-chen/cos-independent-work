{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "\n",
    "# Load the pre-split data\n",
    "train_df = pd.read_csv('csv/pokemon_train.csv')\n",
    "test_df = pd.read_csv('csv/pokemon_test.csv')\n",
    "\n",
    "# Prepare features and targets\n",
    "features = ['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Height(m)', 'Weight(kg)']\n",
    "X_train = train_df[features]\n",
    "X_test = test_df[features]\n",
    "\n",
    "# Prepare targets\n",
    "y_train_primary = train_df['Primary_Type']\n",
    "y_test_primary = test_df['Primary_Type']\n",
    "y_train_generation = train_df['Generation']\n",
    "y_test_generation = test_df['Generation']\n",
    "\n",
    "# Prepare both types for multi-label classification\n",
    "y_train_both = train_df[['Primary_Type', 'Secondary_Type']].values.tolist()\n",
    "y_test_both = test_df[['Primary_Type', 'Secondary_Type']].values.tolist()\n",
    "y_train_both = [[t[0], t[1]] if pd.notna(t[1]) else [t[0]] for t in y_train_both]\n",
    "y_test_both = [[t[0], t[1]] if pd.notna(t[1]) else [t[0]] for t in y_test_both]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Binarize labels for multi-label classification\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_both_bin = mlb.fit_transform(y_train_both)\n",
    "y_test_both_bin = mlb.transform(y_test_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Primary Type Accuracy: 0.2\n",
      "Gradient Boosting - Both Types Hamming Loss: 0.08699186991869919\n",
      "Gradient Boosting - Generation Accuracy: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Baseline without CV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Primary Type\n",
    "gb_primary = GradientBoostingClassifier(random_state=42)\n",
    "gb_primary.fit(X_train_scaled, y_train_primary)\n",
    "y_pred_primary = gb_primary.predict(X_test_scaled)\n",
    "print(\"Gradient Boosting - Primary Type Accuracy:\", accuracy_score(y_test_primary, y_pred_primary))\n",
    "\n",
    "# Both Types\n",
    "gb_both = MultiOutputClassifier(GradientBoostingClassifier(random_state=42))\n",
    "gb_both.fit(X_train_scaled, y_train_both_bin)\n",
    "y_pred_both = gb_both.predict(X_test_scaled)\n",
    "print(\"Gradient Boosting - Both Types Hamming Loss:\", hamming_loss(y_test_both_bin, y_pred_both))\n",
    "\n",
    "# Generation\n",
    "gb_generation = GradientBoostingClassifier(random_state=42)\n",
    "gb_generation.fit(X_train_scaled, y_train_generation)\n",
    "y_pred_generation = gb_generation.predict(X_test_scaled)\n",
    "print(\"Gradient Boosting - Generation Accuracy:\", accuracy_score(y_test_generation, y_pred_generation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Implementation\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Primary Type Prediction\n",
    "gb_primary = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Both Types Prediction\n",
    "gb_both = MultiOutputClassifier(GradientBoostingClassifier(random_state=42))\n",
    "\n",
    "# Generation Prediction\n",
    "gb_generation = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import make_scorer, hamming_loss, accuracy_score, f1_score, jaccard_score\n",
    "\n",
    "def neg_hamming_loss(y_true, y_pred):\n",
    "    return -hamming_loss(y_true, y_pred)\n",
    "\n",
    "hamming_scorer = make_scorer(neg_hamming_loss)\n",
    "\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, param_grid, is_multilabel=False):\n",
    "    # Before tuning\n",
    "    if is_multilabel:\n",
    "        scores_before = cross_val_score(model, X_train, y_train, cv=5, \n",
    "                                        scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "        print(f\"Before tuning - Mean CV Hamming Loss: {-scores_before.mean():.3f} (+/- {scores_before.std() * 2:.3f})\")\n",
    "    else:\n",
    "        scores_before = cross_val_score(model, X_train, y_train, cv=5)\n",
    "        print(f\"Before tuning - Mean CV score: {scores_before.mean():.3f} (+/- {scores_before.std() * 2:.3f})\")\n",
    "\n",
    "    # After tuning\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, \n",
    "                           scoring=hamming_scorer if is_multilabel else 'accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(f\"After tuning - Best cross-validation score: {-grid_search.best_score_:.3f}\" if is_multilabel \n",
    "          else f\"After tuning - Best cross-validation score: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    if is_multilabel:\n",
    "        test_hamming_loss = hamming_loss(y_test, y_pred)\n",
    "        print(f\"Test set Hamming Loss: {test_hamming_loss:.3f}\")\n",
    "        \n",
    "        exact_matches = np.all(y_pred == y_test, axis=1)\n",
    "        exact_match_ratio = np.mean(exact_matches)\n",
    "        print(f\"Exact Match Ratio: {exact_match_ratio:.3f}\")\n",
    "        \n",
    "        jaccard_score_value = jaccard_score(y_test, y_pred, average='samples')\n",
    "        print(f\"Jaccard Similarity Score: {jaccard_score_value:.3f}\")\n",
    "        \n",
    "        f1_score_value = f1_score(y_test, y_pred, average='samples')\n",
    "        print(f\"F1 Score: {f1_score_value:.3f}\")\n",
    "    else:\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Test set accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Define parameter grids\n",
    "param_grid_primary = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "param_grid_both = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__learning_rate': [0.01, 0.1, 0.5],\n",
    "    'estimator__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "param_grid_generation = param_grid_primary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Primary Type Prediction:\n",
      "Before tuning - Mean CV score: 0.187 (+/- 0.043)\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "After tuning - Best cross-validation score: 0.212\n",
      "Test set accuracy: 0.161\n"
     ]
    }
   ],
   "source": [
    "# Primary Type - took around 6 minutes to run\n",
    "print(\"Gradient Boosting - Primary Type Prediction:\")\n",
    "best_gb_primary = train_and_evaluate(gb_primary, X_train_scaled, y_train_primary, \n",
    "                                     X_test_scaled, y_test_primary, param_grid_primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting - Both Types Prediction:\n",
      "Before tuning - Mean CV Hamming Loss: 0.093 (+/- 0.006)\n",
      "Best parameters: {'estimator__learning_rate': 0.01, 'estimator__max_depth': 7, 'estimator__n_estimators': 50}\n",
      "After tuning - Best cross-validation score: 0.085\n",
      "Test set Hamming Loss: 0.081\n",
      "Exact Match Ratio: 0.000\n",
      "Jaccard Similarity Score: 0.000\n",
      "F1 Score: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Both Types - took around 9 minutes and 30 seconds \n",
    "print(\"\\nGradient Boosting - Both Types Prediction:\")\n",
    "best_gb_both = train_and_evaluate(gb_both, X_train_scaled, y_train_both_bin, \n",
    "                                  X_test_scaled, y_test_both_bin, param_grid_both, is_multilabel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting - Generation Prediction:\n",
      "Before tuning - Mean CV score: 0.166 (+/- 0.052)\n",
      "Best parameters: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 100}\n",
      "After tuning - Best cross-validation score: 0.196\n",
      "Test set accuracy: 0.220\n"
     ]
    }
   ],
   "source": [
    "# Generation - took around 5 minutes\n",
    "print(\"\\nGradient Boosting - Generation Prediction:\")\n",
    "best_gb_generation = train_and_evaluate(gb_generation, X_train_scaled, y_train_generation, \n",
    "                                        X_test_scaled, y_test_generation, param_grid_generation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cos397",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
